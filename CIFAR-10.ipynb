{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple convolutional neural network for the CIFAR-10 data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for the convolutional neural network\n",
    "Import libraries for the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries for display, auxilary functions, and the extraction of the CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for the extraction of the CIFAR-10 data. The dictionary that is returned consists of:\n",
    "    - 'data':   10,000 x 3072 numpy array\n",
    "                Each row represents a picture with 3072 = 1024 x 3\n",
    "                correspond to the different color channels and 1024 is a\n",
    "                flattened 32 x 32 array\n",
    "    - 'labels': The 10,000 corresponding labels ranging between 0 .. 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the training data and its labels and reshape the data such that it is compatible with the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUTPATH = os.getcwd() + \"/CIFAR-10/\"\n",
    "train = unpickle(INPUTPATH + \"data_batch_1\")\n",
    "\n",
    "x_train = train['data']\n",
    "y_train = np.array(train['labels'])\n",
    "\n",
    "x_train = np.reshape(x_train,(10000,3,32,32))\n",
    "x_train = np.transpose(x_train,(0,3,1,2))\n",
    "x_train = np.transpose(x_train,(0,1,3,2))\n",
    "x_train = x_train/255.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example plot of one training file with its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nITJFwS9Epij4hcgUBb8QmfL/AAlYvsUFlKHIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa70d1f55d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[20,:,:,:])\n",
    "print(y_train[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test data in the same manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = unpickle(INPUTPATH + \"test_batch\")\n",
    "\n",
    "x_test = test['data']\n",
    "y_test = np.array(test['labels'])\n",
    "\n",
    "x_test = np.reshape(x_test,(10000,3,32,32))\n",
    "x_test = np.transpose(x_test,(0,3,1,2))\n",
    "x_test = np.transpose(x_test,(0,1,3,2))\n",
    "x_test = x_test/255.\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 29s - loss: 1.9742    \n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 27s - loss: 1.6201    \n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 26s - loss: 1.4472    \n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 27s - loss: 1.3343    \n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 26s - loss: 1.2453    \n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 27s - loss: 1.1523    \n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 25s - loss: 1.0660    \n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.9760    \n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.8995    \n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.8126    \n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.7489    \n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.6606    \n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.6049    \n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.5325    \n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.4883    \n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.4467    \n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.4238    \n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.3686    \n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.3403    \n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.3213    \n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.2899    \n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.2918    \n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.2554    \n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.2443    \n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.2246    \n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 25s - loss: 0.2120    \n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 26s - loss: 0.2107    \n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.1915    \n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.1856    \n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.1757    \n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.1828    \n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.1592    \n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.1644    \n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.1543    - ETA:\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.1465    \n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 27s - loss: 0.1538    \n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.1396    \n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.1294    \n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 32s - loss: 0.1355    \n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.1288    \n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.1169    \n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 32s - loss: 0.1093    \n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.0998    \n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.1125    \n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 32s - loss: 0.1026    \n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.1123    \n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.1051    - E\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.0865    \n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.0969    \n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.0962    \n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 31s - loss: 0.1002    \n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0935    \n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0961    \n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 27s - loss: 0.0904    \n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.0736    \n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0855    \n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0723    \n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0853    \n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0744    \n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0816    \n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0759    \n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0768    \n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0860    \n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0777    \n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0724    \n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.0666    \n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0652    \n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.0720    \n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 30s - loss: 0.0645    \n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0622    \n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0666    \n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0602    \n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0732    \n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0645    \n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0631    \n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0598    \n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0479    \n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0635    \n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0665    \n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0522    \n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0418    \n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0475    \n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0628    \n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0591    \n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 29s - loss: 0.0560    \n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0575    \n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0570    \n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0520    \n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0597    \n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0478    \n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0460    \n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0527    \n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0550    \n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0398    \n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0408    \n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0505    \n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0474    \n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 28s - loss: 0.0470    \n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 28s - loss: 0.0582    \n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 27s - loss: 0.0547    \n",
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=100)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CIFAR-10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
